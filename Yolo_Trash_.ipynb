{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajat504/CLOUDYML/blob/main/Yolo_Trash_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X9ksJWOYv6O"
      },
      "source": [
        "<center><h1><u>YOLO (You Only Look Once)</center></h1></u>\n",
        "\n",
        "You Only Look Once (YOLO) is an algorithm proposed by Redmond et al in a research study published as a conference paper at the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), which won the OpenCV People's Choice Award.\n",
        "\n",
        "YOLO proposes the usage of an end-to-end neural network that provides predictions of bounding boxes and class probabilities all at once, as opposed to the method followed by object detection algorithms before YOLO, which repurposed classifiers to perform detection.\n",
        "![cv1.jpg](data:image/jpeg;base64,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)\n",
        "\n",
        "Under YOLO,you will be working on Trash detection project wherein the model will detect whether the image contains trash or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6gKFm83wNtd"
      },
      "outputs": [],
      "source": [
        "###Refer Video\n",
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('ag3DLKsl2vk', width=700, height=400)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZl4RBrHwNth"
      },
      "source": [
        "<h2><u>Roadmap for the project</h2></u>\n",
        "\n",
        "* Installing YOLO and other dependencies\n",
        "* Getting the data and processing it\n",
        "* Data Annotation\n",
        "* Creating bounding boxes\n",
        "* Train the different YOLO models\n",
        "* Implement Tensorboard\n",
        "* making predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgI_hDpawNtj",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "###Refer Video\n",
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('GRtgLlwxpc4', width=700, height=400)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "254YtROwwNtk"
      },
      "source": [
        "## Note: Implement the notebook in Jupyter Notebook if you are not able to do it in Google Colab.\n",
        "### **Download the dataset and upload it in your drive:** https://www.kaggle.com/kneroma/tacotrashdataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "b8pyl2gfQEmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr5b0RL9Y7GY"
      },
      "source": [
        "### Connect the Google drive\n",
        "\n",
        "The dataset used in the project is present in the google drive. So the drive has to be first mounted to use the dataset. For that use the drive library from google.colab and then mount the drive using mount function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M__1L7ByQFbO"
      },
      "outputs": [],
      "source": [
        "# import drive from google.colab\n",
        "from google.colab import drive\n",
        "# mount the drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMoA2ewPZAI2"
      },
      "source": [
        "Move the location to Trash detection folder (choose location where you have trash detection data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1h0ZlHxplpDi"
      },
      "outputs": [],
      "source": [
        "# move location\n",
        "%cd /content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m-lGrWLZPYP"
      },
      "source": [
        "Download the dataset from google drive in zipped form and unzip it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoKrxw7BcKng"
      },
      "outputs": [],
      "source": [
        "#!unzip \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/archive.zip\" -d \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/unzipped_taco_dataset.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLqB12h4cKyo"
      },
      "outputs": [],
      "source": [
        "#!unzip \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/taco_saved_files.zip\" -d \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/unzipped_taco_saved_files.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYfqPM9FZYzf"
      },
      "source": [
        "Clone the YoloV5 github for using its architecture and for detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVVd3JfnZv4-"
      },
      "source": [
        "*YOLOv5 ðŸš€ is a family of object detection architectures and models pretrained on the COCO dataset, and represents Ultralytics open-source research into future vision AI methods, incorporating lessons learned and best practices evolved over thousands of hours of research and development.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1PiylREZ2gC"
      },
      "source": [
        "Documentation\n",
        "See the [YOLOv5 Docs](https://docs.ultralytics.com/) for full documentation on training, testing and deployment. bold text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orxJeu_nZ2c3"
      },
      "source": [
        "### **Step 1: Install Yolo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YMGZ62ZaYrF"
      },
      "source": [
        "\n",
        "\n",
        "1.  Clone the Yolo repository.\n",
        "2.  Go to yolov5 folder.\n",
        "3.  Install all the requirements for running the architecture.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXEh8PhRQi5v"
      },
      "outputs": [],
      "source": [
        "#!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "#go to yolov5\n",
        "%cd yolov5\n",
        " # install\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9aqGXE8axvh"
      },
      "source": [
        "**Install pycocotools\n",
        "(pycocotools is a Python API that assists in loading, parsing and visualizing the annotations in COCO.)**\n",
        "\n",
        "Refer: https://pypi.org/project/pycocotools/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhEDLOjWQi-5"
      },
      "outputs": [],
      "source": [
        "#install pycocotools\n",
        "!pip install pycocotools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xF2jGMt-Va3i"
      },
      "outputs": [],
      "source": [
        "#change directory to trash detection folder\n",
        "%cd /content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb6__P-Kc7CX"
      },
      "source": [
        "### **Import the required libraries**\n",
        "\n",
        "* torch: for tensor computation\n",
        "* Image: for working with images\n",
        "* os: to handle and work with the operating system\n",
        "* random: used to generate random numbers,https://docs.python.org/3/library/random.html\n",
        "* shutil: offers high-level operation on a file like a copy, create, and remote operation on the file,https://docs.python.org/3/library/shutil.html\n",
        "* train_test_split: to split the data into training and testing data\n",
        "* ElementTree: represents the whole XML document as a tree,https://docs.python.org/3/library/xml.etree.elementtree.html\n",
        "* minidom: implementation of the Document Object Model interface, https://docs.python.org/3/library/xml.dom.minidom.html\n",
        "* tqdm: used for creating Progress Meters or Progress Bars,https://tqdm.github.io/\n",
        "* ImageDraw: provides simple 2D graphics for Image objects,https://pillow.readthedocs.io/en/stable/reference/ImageDraw.html\n",
        "* numpy: for array and matrix operations\n",
        "* matplotlib: for visualizations\n",
        "* yolov5.utils: https://github.com/ultralytics/yolov5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qr requirements.txt\n"
      ],
      "metadata": {
        "id": "AbySL3POOszv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJm-LGh6QjCK"
      },
      "outputs": [],
      "source": [
        "#install above mentioned libraries\n",
        "import torch\n",
        "from IPython.display import Image  # for displaying images\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xml.etree.ElementTree as ET\n",
        "from xml.dom import minidom\n",
        "import tqdm\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#from yolov5 import utils\n",
        "#set random seed to 108\n",
        "random.seed(108)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCRBuWxudBJf"
      },
      "source": [
        "The cat command allows us to create single or multiple files, view contain of file, concatenate files and redirect output in terminal or files.\n",
        "Use cat to view dataset in json format and for custom datas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsV87GMydP4G"
      },
      "outputs": [],
      "source": [
        "#view annotations.json using cat command\n",
        "!cat \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/unzipped_taco_dataset/data/annotations.json\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfUg709keLd9"
      },
      "source": [
        "### <u>Train On Custom Data</u>\n",
        "\n",
        "1. Create dataset.yaml.\n",
        "2. [COCO128](https://www.kaggle.com/ultralytics/coco128) is a small tutorial dataset composed of the first 128 images in COCO train2017.\n",
        "3. These same 128 images are used for both training and validation to verify our training pipeline is capable of overfitting. data/coco128.\n",
        "4. yaml, shown below, is the dataset configuration file that defines\n",
        "\n",
        ">* an optional download command/URL for auto-downloading,\n",
        ">* a path to a directory of training images (or path to a *.txt file with a list of training images),\n",
        ">* the same for our validation images,\n",
        ">* the number of classes,\n",
        ">* a list of class names:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HP07BugzQjFc"
      },
      "outputs": [],
      "source": [
        "#import COCO\n",
        "from pycocotools.coco import COCO\n",
        "#load the annotations.json using COCO\n",
        "data_source = COCO(annotation_file='/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/unzipped_taco_dataset/data/annotations.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wuZcyeoe8sU"
      },
      "source": [
        "**Check all the categories availiable in given trash detection dataset with id and categories**\n",
        "\n",
        "Use the 'cats' method to do so."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IKrp_efQjIF"
      },
      "outputs": [],
      "source": [
        "#view categories\n",
        "data_source.cats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtLr1j6ggdAc"
      },
      "source": [
        "**Extract names from given dataset and print it**\n",
        "\n",
        "Now extract the categories of trash from the given data by iterating through it and extracting the name attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mASPIn2QjK9"
      },
      "outputs": [],
      "source": [
        "#iterate using enumerate\n",
        "for k, count in enumerate(data_source.cats):\n",
        "  #print the number of category and name of trash\n",
        "  print(count, ' ', data_source.cats[k]['name'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyLtw3r9gkCu"
      },
      "source": [
        "We see there are 59 categories of trash.\n",
        "Create a dictionary named as label_transfer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rpmn3Z16QjN3"
      },
      "outputs": [],
      "source": [
        "#label_transfer = {5: 0, 12: 1}\n",
        "label_transfer = {5: 0, 12: 1}\n",
        "label_transfer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmHN4e7DhfFN"
      },
      "source": [
        "coco returns the dictionary of the dataset. Here we can get id's of images with coco.getImgIds() function, after getting image id's we have to load those images for loading the images we can use coco.loadImgs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAwhZUwAQjQu"
      },
      "outputs": [],
      "source": [
        "#get the image IDs\n",
        "img_ids = data_source.getImgIds()\n",
        "img_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbk0v8aPh9tN"
      },
      "source": [
        "**Category IDs gives number of unique ids in given dataset format**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmXRBtK-QjTl"
      },
      "outputs": [],
      "source": [
        "#get category IDs\n",
        "catIds = data_source.getCatIds()\n",
        "catIds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGbxcbJMiZH9"
      },
      "source": [
        "Loading categories using catIds for finding category names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqHoqIh1QjWf"
      },
      "outputs": [],
      "source": [
        "#use loadCats methods and pass the extracted category IDs\n",
        "categories = data_source.loadCats(catIds)\n",
        "categories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77wHQkcei0eM"
      },
      "source": [
        "Sort category based on id using [lambda](https://www.w3schools.com/python/python_lambda.asp) functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trsi2-XFQjZl"
      },
      "outputs": [],
      "source": [
        "#sort the categories\n",
        "categories.sort(key=lambda x: x['id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOs-XbrYjDPl"
      },
      "source": [
        "Create an empty dictonary for labels, classes, label inverse that we need to find in our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xN1jHgPNgH-I"
      },
      "outputs": [],
      "source": [
        "#create classes dictionary\n",
        "classes = {}\n",
        "#create coco_labels dictionary\n",
        "coco_labels = {}\n",
        "#create coco_labels_inverse dictionary\n",
        "coco_labels_inverse = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVLFctHIwNuP"
      },
      "source": [
        "Next run a for loop iterating through the sorted categories. Store the category IDs in coco_labels dictionary(keys as len(classes) and values as category ID) and IDs in inverse order in the coco_labels_inverse dictionary(keys as category ID and values as len(classes)). Store the length of classes in classes dictionary(keys as category name and values as len(classes))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8deSIcSgJ54"
      },
      "outputs": [],
      "source": [
        "#iterate through categories\n",
        "for c in categories:\n",
        "    #store category IDs in coco_labels(keys-->len(classes))\n",
        "    coco_labels[len(classes)] = c['id']\n",
        "    #store len(classes) in coco_labels_inverse(keys-->c['id'])\n",
        "    coco_labels_inverse[c['id']] = len(classes)\n",
        "    #store len(classes) in classes(keys-->c['name'])\n",
        "    classes[c['name']] = len(classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK9SAP4RwNuR"
      },
      "source": [
        "View the classes dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXHMNs5hgLv7"
      },
      "outputs": [],
      "source": [
        "#print classes\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9RimRyygObT"
      },
      "outputs": [],
      "source": [
        "class_num = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huh80qDfj0ab"
      },
      "source": [
        "Create a new directory for storing images and labels using the mkdir command(make directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkhVCEDygRMk"
      },
      "outputs": [],
      "source": [
        "#!mkdir -p tmp/labels tmp/images\n",
        "!mkdir -p tmp/labels tmp/images\n",
        "#save_base_path  = 'tmp/labels/'\n",
        "save_base_path  = 'tmp/labels/'\n",
        "#save_image_path = 'tmp/images/'\n",
        "save_image_path = 'tmp/images/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11Nza7HWj_1l"
      },
      "source": [
        "Convert .json file to .txt file\n",
        "Annotate the images using the .txt file obtained and make a binding box aroung the object."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLdUZsAskmhM"
      },
      "source": [
        "### **Bounding Boxes**\n",
        "In object detection, we usually use a bounding box to describe the spatial location of an object. The bounding box is rectangular, which is determined by the  x  and  y  coordinates of the upper-left corner of the rectangle and the such coordinates of the lower-right corner. Another commonly used bounding box representation is the  (x,y) -axis coordinates of the bounding box center, and the width and height of the box.<br><br>\n",
        "- The code starts by enumerating all the images in a data source.\n",
        "- The first one is img_id=0, which is the image that was loaded from the data source.\n",
        "- Then it creates a variable called \"img_info\" and stores the information about this image in it.\n",
        "- Next, it saves this image's file name to a new file with \"_\" as its extension so that when you open up this text file later on, you can see what changes were made to your original .json file.\n",
        "\n",
        "- Next, it creates another variable called \"save_name\".\n",
        "- This will be used for saving any other files that are created during this process of changing an existing json file into a txt-file.\n",
        "- It then uses split() to separate out the filename from its extension and store them separately in variables called height and width respectively.\n",
        "- Finally, save_base_path + filename + '.txt' is saved to disk at whatever location you want (I chose my desktop).\n",
        "\n",
        "- The next line checks if there already exists an empty text document with these two variables as its name; if not then create one now using open().- The code will change the .json file to a .txt file.- The code starts by loading the data from the file.\n",
        "- The code then goes through each of the annotations and labels them with their corresponding class number.\n",
        "- If there is an annotation that does not have a label, it will be labeled as 0.\n",
        "- The next part of the code loops through all of the boxes in each annotation and writes out its coordinates to a list called lines.- The code attempts to create a list of the annotation ids that are present in the image.\n",
        "\n",
        "- The code then iterates through each annotation id and loads it from the data source.\n",
        "\n",
        "- Next, it creates a list of strings which will be used as labels for each box in the plot.\n",
        "\n",
        "- Lastly, if there are any annotations that have not been transferred yet, they will be added to class_num with a label of 0 and 1 respectively.\n",
        "â€“\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Y19s7T4gTBu"
      },
      "outputs": [],
      "source": [
        "#iterate through image IDs and show tqdm progress bar\n",
        "#for index, img_id in tqdm.tqdm(enumerate(img_ids), desc='change .json file to .txt file')\n",
        "for index, img_id in tqdm.tqdm(enumerate(img_ids), desc='change .json file to .txt file'):\n",
        "    #get image info,data_source.loadImgs(img_id)[0]\n",
        "    img_info = data_source.loadImgs(img_id)[0]\n",
        "    #replace '/' with '_' in file name of images\n",
        "    save_name = img_info['file_name'].replace('/', '_')\n",
        "    #split the file name based on '.'\n",
        "    file_name = save_name.split('.')[0]\n",
        "   #get height of image\n",
        "    height = img_info['height']\n",
        "    #get width of image\n",
        "    width = img_info['width']\n",
        "    #save new path of image\n",
        "    #save_path = save_base_path + file_name + '.txt'\n",
        "    save_path = save_base_path + file_name + '.txt'\n",
        "    #set is_exist to False\n",
        "    is_exist = False\n",
        "    #open the saved path in write mode\n",
        "    with open(save_path, mode='w') as fp:\n",
        "        #get the annotation ID\n",
        "        annotation_id = data_source.getAnnIds(img_id)\n",
        "        #create boxes,np.zeros((0, 5))\n",
        "        boxes = np.zeros((0, 5))\n",
        "        #check if length of annotation IDs is 0\n",
        "        if len(annotation_id) == 0:\n",
        "            #insert ''\n",
        "            #fp.write('')\n",
        "            fp.write('')\n",
        "            #continue\n",
        "            continue\n",
        "        #load annotations\n",
        "        #annotations = data_source.loadAnns(annotation_id)\n",
        "        annotations = data_source.loadAnns(annotation_id)\n",
        "        #set a blank string 'lines'\n",
        "        lines = ''\n",
        "        #iterate through annotations\n",
        "        for annotation in annotations:\n",
        "            #extract label from coco_labels_inverse\n",
        "            #label = coco_labels_inverse[annotation['category_id']]\n",
        "            label = coco_labels_inverse[annotation['category_id']]\n",
        "            #if label in label_transfer.keys():\n",
        "            if label in label_transfer.keys():\n",
        "                #set is_exist to True\n",
        "                is_exist = True\n",
        "                #get bbox of annotation\n",
        "                #box = annotation['bbox']\n",
        "                box = annotation['bbox']\n",
        "                #check if box[2] < 1 or box[3] < 1:\n",
        "                if box[2] < 1 or box[3] < 1:\n",
        "                   #continue\n",
        "                    continue\n",
        "                #create boxes\n",
        "                # box[0] = round((box[0] + box[2] / 2) / width, 6)\n",
        "                #box[1] = round((box[1] + box[3] / 2) / height, 6)\n",
        "                #box[2] = round(box[2] / width, 6)\n",
        "                #box[3] = round(box[3] / height, 6)\n",
        "                box[0] = round((box[0] + box[2] / 2) / width, 6)\n",
        "                box[1] = round((box[1] + box[3] / 2) / height, 6)\n",
        "                box[2] = round(box[2] / width, 6)\n",
        "                box[3] = round(box[3] / height, 6)\n",
        "                #label = label_transfer[label]\n",
        "                label = label_transfer[label]\n",
        "                #check if label is present in classes\n",
        "                #if label not in class_num.keys():\n",
        "                if label not in class_num.keys():\n",
        "                    #class_num[label] = 0\n",
        "                    class_num[label] = 0\n",
        "                #increment class_num[label]\n",
        "                class_num[label] += 1\n",
        "                #add the string of label to lines\n",
        "                lines = lines + str(label)\n",
        "                #iterate through box\n",
        "                #for i in box:\n",
        "                for i in box:\n",
        "                    #add the string of each box in lines\n",
        "                    #lines += ' ' + str(i)\n",
        "                    lines += ' ' + str(i)\n",
        "                #add a blank line in lines\n",
        "                lines += '\\n'\n",
        "        #add these lines to the file\n",
        "        #fp.writelines(lines)\n",
        "        fp.writelines(lines)\n",
        "    #check if is_exist is True\n",
        "    if is_exist:\n",
        "        #copy the dataset paths and image paths\n",
        "        #shutil.copy('/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/unzipped_taco_dataset/data/{}'.format(img_info['file_name']), os.path.join(save_image_path, save_name))\n",
        "        shutil.copy('/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/unzipped_taco_dataset/data/{}'.format(img_info['file_name']), os.path.join(save_image_path, save_name))\n",
        "    #else\n",
        "    else:\n",
        "        #remove save_path\n",
        "        os.remove(save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYVNrQQBk7xE"
      },
      "source": [
        "### **Split the dataset into train test valid using split-folder library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGlrZ_tegjqN"
      },
      "outputs": [],
      "source": [
        "#install split-folders\n",
        "!pip install split-folders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85o-6APylF9T"
      },
      "source": [
        "#Split data into:-\n",
        "80% train <br>\n",
        "10% test<br>\n",
        "10% validate\n",
        "\n",
        "https://pypi.org/project/split-folders/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VV3Mgmmvglt1"
      },
      "outputs": [],
      "source": [
        "#import splitfolders\n",
        "import splitfolders\n",
        "#split the folders\n",
        "#splitfolders.ratio('tmp', output=\"taco\", seed=1337, ratio=(.8, 0.1,0.1))\n",
        "splitfolders.ratio('tmp', output=\"taco\", seed=1337, ratio=(.8, 0.1,0.1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDnvtwKJlZXC"
      },
      "source": [
        "### **Train the model created**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVuhc6a5lqO7"
      },
      "source": [
        "* The commands below reproduce YOLOv5 COCO results. Models and datasets download automatically from the latest YOLOv5 release.\n",
        "* Training times for YOLOv5n/s/m/l/x are 1/2/4/6/8 days on a V100 GPU (Multi-GPU times faster).\n",
        "* Use the largest --batch-size possible, or pass --batch-size -1 for YOLOv5 AutoBatch.\n",
        "* Batch sizes shown for V100-16GB.\n",
        "\n",
        "python train.py --data coco.yaml --cfg yolov5n.yaml --weights '' --batch-size 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNZaDpJXm77e"
      },
      "source": [
        "\n",
        "|Model |size<br><sup>(pixels) |mAP<sup>val<br>0.5:0.95 |mAP<sup>val<br>0.5 |Speed<br><sup>CPU b1<br>(ms) |Speed<br><sup>V100 b1<br>(ms) |Speed<br><sup>V100 b32<br>(ms) |params<br><sup>(M) |FLOPs<br><sup>@640 (B)\n",
        "|---                    |---  |---    |---    |---    |---    |---    |---    |---\n",
        "|[YOLOv5n][assets]      |640  |28.4   |46.0   |**45** |**6.3**|**0.6**|**1.9**|**4.5**\n",
        "|[YOLOv5s][assets]      |640  |37.2   |56.0   |98     |6.4    |0.9    |7.2    |16.5\n",
        "|[YOLOv5m][assets]      |640  |45.2   |63.9   |224    |8.2    |1.7    |21.2   |49.0\n",
        "|[YOLOv5l][assets]      |640  |48.8   |67.2   |430    |10.1   |2.7    |46.5   |109.1\n",
        "|[YOLOv5x][assets]      |640  |50.7   |68.9   |766    |12.1   |4.8    |86.7   |205.7\n",
        "|                       |     |       |       |       |       |       |       |\n",
        "|[YOLOv5n6][assets]     |1280 |34.0   |50.7   |153    |8.1    |2.1    |3.2    |4.6\n",
        "|[YOLOv5s6][assets]     |1280 |44.5   |63.0   |385    |8.2    |3.6    |12.6   |16.8\n",
        "|[YOLOv5m6][assets]     |1280 |51.0   |69.0   |887    |11.1   |6.8    |35.7   |50.0\n",
        "|[YOLOv5l6][assets]     |1280 |53.6   |71.6   |1784   |15.8   |10.5   |76.7   |111.4\n",
        "|[YOLOv5x6][assets]<br>+ [TTA][TTA]|1280<br>1536 |54.7<br>**55.4** |**72.4**<br>72.3 |3136<br>- |26.2<br>- |19.4<br>- |140.7<br>- |209.8<br>-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPvRsAxPmWVM"
      },
      "source": [
        "# Different Yolo models comparisons\n",
        "<a href=\"https://ibb.co/26nzD5T\"><img src=\"https://i.ibb.co/8BKyWXH/model-comparison.png\" alt=\"model-comparison\" border=\"0\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMjNdUCxnLWT"
      },
      "source": [
        "Train a YOLOv5s model on COCO128 by specifying dataset, batch-size, image size and either pretrained --weights yolov5s.pt (recommended), or randomly initialized --weights '' --cfg yolov5s.yaml (not recommended). Pretrained weights are auto-downloaded from the latest YOLOv5 release.\n",
        "\n",
        "Example for training YOLOv5s on COCO128 for 3 epochs<br>\n",
        "$ python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt\n",
        "\n",
        "All training results are saved to runs/train/ with incrementing run directories, i.e. runs/train/exp2, runs/train/exp3 etc. For more details see the Training section of our tutorial notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aWmegZn1VrX"
      },
      "outputs": [],
      "source": [
        "#!python /content/drive/MyDrive/ColabNote/trash_detect/yolov5/train.py --img 320 --batch 1 --epochs 10 --data /content/drive/MyDrive/ColabNote/trash_detect/yolov5/taco8.yaml --cfg /content/drive/MyDrive/ColabNote/trash_detect/yolov5/models/yolov5s.yaml --weights yolov5s.pt --cache\n",
        "!python \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/train.py\" --img 320 --batch 1 --epochs 10 --data \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/taco8.yaml\" --cfg \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/models/yolov5s.yaml\" --weights yolov5s.pt --cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRh7myDHnlNy"
      },
      "source": [
        "# [Tensorboard](https://www.tensorflow.org/tensorboard/get_started)\n",
        "##Local Logging<br>\n",
        "All results are logged by default to runs/train, with a new experiment directory created for each new training as runs/train/exp2, runs/train/exp3, etc. View train and val jpgs to see mosaics, labels, predictions and augmentation effects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdh9P4gennyD"
      },
      "source": [
        "TensorBoard provides the visualization and tooling needed for machine learning experimentation:\n",
        "* Tracking and visualizing metrics such as loss and accuracy\n",
        "* Visualizing the model graph (ops and layers)\n",
        "* Viewing histograms of weights, biases, or other tensors as they change over time\n",
        "* Projecting embeddings to a lower dimensional space\n",
        "* Displaying images, text, and audio data\n",
        "* Profiling TensorFlow programs\n",
        "\n",
        "Refer:https://www.tensorflow.org/tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CG7Dq9mY6McB"
      },
      "outputs": [],
      "source": [
        "# Tensorboard  (optional)\n",
        "#%load_ext tensorboard\n",
        "#%tensorboard --logdir /content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/runs/train\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/runs/train\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYw4Jf_YBKAF"
      },
      "outputs": [],
      "source": [
        "#copy weights\n",
        "#!cp /content/drive/MyDrive/ColabNote/trash_detect/yolov5/runs/train/exp/weights/best.pt\n",
        "!cp \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/runs/train/exp2/weights/best.pt\" weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_bKt6A-1Vhf"
      },
      "outputs": [],
      "source": [
        "#view files\n",
        "#!ls /content/drive/MyDrive/ColabNote/trash_detect/taco/val/images\n",
        "!ls \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/taco/val/images\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNw2-U44oPJd"
      },
      "source": [
        "Use ipython library to display the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GGV-IBY_B_k"
      },
      "outputs": [],
      "source": [
        "#import Image\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuNSpNLvANA8"
      },
      "source": [
        "Lets check sample images in our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX4UM9AI_CFa"
      },
      "outputs": [],
      "source": [
        "#display any image\n",
        "Image('taco/val/images/batch_13_000009.jpg', width=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLdB6mJ2AYLe"
      },
      "source": [
        "### **Lets make our predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySZbzW5L_CI2"
      },
      "outputs": [],
      "source": [
        "#!python \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/detect.py\" --weights \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/runs/train/exp/weights/best.pt\" --img 416 --conf 0.1 --source \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/taco/val/images\"\n",
        "!python \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/detect.py\" --weights \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/runs/train/exp2/weights/best.pt\" --img 416 --conf 0.1 --source \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/taco/val/images\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQzX66X__CLH"
      },
      "outputs": [],
      "source": [
        "#!python \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/detect.py\" --weights \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/runs/train/exp/weights/best.pt\" --img 416 --conf 0.1 --source \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/taco/test/yolov5/detect.py\" --weights \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/runs/train/exp/weights/best.pt\" --img 416 --conf 0.1 --source \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/taco/test/images\"\n",
        "!python \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/detect.py\" --weights \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/runs/train/exp2/weights/best.pt\" --img 416 --conf 0.1 --source \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/taco/test/yolov5/detect.py\" --weights \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/runs/train/exp2/weights/best.pt\" --img 416 --conf 0.1 --source \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/taco/test/images\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SzADOpg_CNf"
      },
      "outputs": [],
      "source": [
        "#!python \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/detect.py\" --source \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/taco/train/images/batch_10_000015.jpg\" --weights \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/runs/train/exp/weights/best.pt\"\n",
        "!python \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/detect.py\" --source \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/taco/train/images/batch_10_000015.jpg\" --weights \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/runs/train/exp2/weights/best.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnicqBa-1VGi"
      },
      "outputs": [],
      "source": [
        "# first, display our ground truth data\n",
        "Image(filename= \"/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/runs/train/exp2/val_batch0_pred.jpg\" , width=400 , height=400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IhXVIsuhTid"
      },
      "outputs": [],
      "source": [
        "# first, display our ground truth data\n",
        "Image(filename='/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/runs/train/exp2/train_batch0.jpg' , width=400 , height=400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "da6dFE7H-43d"
      },
      "outputs": [],
      "source": [
        "# first, display our ground truth data\n",
        "Image(filename='/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/runs/detect/exp5/batch_1_000115.JPG' , width=400 , height=400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgpRj3nI_s3c"
      },
      "outputs": [],
      "source": [
        "# first, display our ground truth data\n",
        "Image(filename='/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/runs/detect/exp5/batch_7_000082.JPG' , width=400 , height=400)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFFYggcgwNu-"
      },
      "source": [
        "Hence we can observe that trash is detected and bounding boxes are drawn around it. Lets display all the images. Import glob,the glob module is used to retrieve files/pathnames matching a specified pattern.https://www.geeksforgeeks.org/how-to-use-glob-function-to-find-files-recursively-in-python/."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMSJr3X0_8o-"
      },
      "outputs": [],
      "source": [
        "#import glob,Image and display\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "#iterate through images\n",
        "#for imageName in glob.glob('/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/runs/detect/exp5/*.jpg'):\n",
        "for imageName in glob.glob('/content/drive/MyDrive/CloudyML_Time Series Analysis/Trash Detection/yolov5/runs/detect/exp5/*.jpg'): #assuming JPG\n",
        "    #display the image\n",
        "    display(Image(filename=imageName , height=500, width=500))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBcCMLSxAp4E"
      },
      "source": [
        "### Congratulations!!! You've done it.\n",
        "\n",
        "In this assignment you implemented:\n",
        "\n",
        "* YOLO\n",
        "* Trash detection project\n",
        "\n",
        "\n",
        "Keep practising!!<br><br>\n",
        "\n",
        "## Do fill the feedback form given below:\n",
        "[Feedback form](https://forms.zohopublic.in/cloudyml/form/CloudyMLDeepLearningFeedbackForm/formperma/VCFbldnXAnbcgAIl0lWv2blgHdSldheO4RfktMdgK7)\n",
        "<br><br>\n",
        "![Goodbye-Keep-Up-The-Good-Work-Good-Bye-Meme.jpg](https://m.media-amazon.com/images/I/31Tvvzb1dDL.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsFcqQABwNvB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}